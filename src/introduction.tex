\section{Introduction}


The growth of web platforms is partially caused by Internet's capacity to stimulate services development, allowing very quick release of minimal viable products.
In a matter of hours, it is possible to upload a first product and start gathering a user community around.
\textit{``Release early, release often''} is commonly heard as an advice to quickly gather a user community, as the size of the community is a factor of success.

If the service complies successfully with users requirements, the community will grow gradually as the service gain popularity.
To cope with this growth, the resources quantity taken up by the service shall grow exponentially.
This continues until the amount of data to process requires the development team to use a more efficient processing model.  %to make better use of the resources.
Many of the most efficient models split the system into parts to reduce their coupling and migrate them to more resourceful environment.
They are also based on a cluster of commodity machines\cite{Fox1997} to allow incremental scalability.
The Staged Event-driven Architecture (SEDA)\cite{Welsh2000} and MapReduce \cite{Dean2008} are example of this trend.
Once split, the different service's parts are connected by a messaging system, often asynchronous, using communication paradigms like \textit{three-tiers} architecture, events, messages or streams.
Many tools have been developed to express and manage these different service's parts and their communications.
We can cite Spark \cite{Zaharia2010}, MillWheel \cite{Akidau2013}, Timestream \cite{Qian2013} and Storm \cite{Marz2011}.
However these tools use specific interfaces and languages, usually different than the tools used in the early step of a project.
Thus, it requires the development team to be trained, to hire experts and to start over the initial code base, while this new architecture is not as flexible and adaptable for quick modifications, as the initial code base was.
Thus, these modifications implies the development team to take risks without adding concrete value to the service.

% We propose a tool able to automate this technical shift without the need of an architecture shift.
We propose a tool able to automate this shift enabling scalability, without the need for a shift in the code base implying the development team to build around scalability problematics.
Such a tool might lift the risks described above.
We aim at providing this tool to Web applications for which load comes from users requests streams.
Applications for which initial development uses a simple web paradigm consisting of a web server, data processing logic, and a database.
We think that it is possible to analyze this type of application to express it using autonomous, movable functions communicating by data streams.
And to shift architecture as soon as the first public release, without wiping off the initial code base.

We assume these applications are developed in a dynamic language like Javascript using \textit{Node.js} execution environment, and we propose a tool able to identify internal streams and stream processing units, and to dynamically manage these units.
The tool aims not to modify the existing code, but proposes a layer of meta information over the initial code.
This layer uses the paradigm of fluxion which we define in section \ref{section:model}, and will be at the core of our proposition of automation, described section \ref{section:compiler}.
Section \ref{section:related}, we link our work with related works.
Finally, we conclude this paper in section \ref{section:conclusion}.