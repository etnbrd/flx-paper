\section{Fluxional execution model} \label{section:model}

Many frameworks for distributed systems are renowned for their performances\cite{Welsh2000, Jain2006, Wu2007, Zaharia2010, Akidau2013, Marz2011}.
However, we focus on a compilation approach to replace the shift in programming model rather than the performance of the runtime.
We present in this section an extremely simplified but generic execution model inspired by the literature, only to support the confirmation of feasibility for the compilation process detailed in section \ref{section:compiler}.
The execution model is not distributed on remote machines, however it isolates the execution of fluxions in different process to reproduce the execution conditions of a distributed execution model.
We are interested in the problems arising from this isolation.

\subsection{Fluxions and workers}

The fluxional execution model manages and invokes autonomous execution units named fluxion $\bnfpn{flx}$.
A fluxion is composed of a unique name $\bnfpn{id}$, a processing function $\bnfpn{fn}$, and a persisted memory called a \textit{context} $\bnfpn{ctx}$.
It is a function $\bnfpn{fn}$ consuming an input stream $\bnfpn{stream}$ and generating one or more outputs streams to other fluxions $\bnfpn{dest}$.
It listens for, and sends back continuous sequence of messages.
The \textit{context} persists the state on which a fluxion rely between two message receptions.
At a message reception, the fluxion modifies its \textit{context}, and sends back messages to downstream fluxions.
A message is composed of the recipient fluxions' names and a body.

Fluxions are executed on workers.
A worker is an event-loop and an isolated heap ; it is a \textit{Node.js} instance.

The context of a fluxion is lexically isolated.
It has a distinct lexical scope containing variables not shared with any other fluxion.
Fluxions on the same worker share the same event-loop, and the same heap ; they send references to each over.
Fluxions on different workers have different event-loop and heaps ; their communications are serialized, so it impossible to send heap references.
The event-loop assures the exclusivity and atomicity of operations of each fluxion on the heap.
This organization shows that the more the memory is shared, the harder it is to distribute fluxions on different workers to allow parallelisation of their execution.

We represent here the syntax of a high-level language to represent a program in the fluxionnal form.
It is the target for our compiler.

\begin{bnf*}
  \bnfprod{program}    {\bnfpn{flx} \bnfor \bnfpn{flx} \bnfsp \bnftd{eol} \bnfsp \bnfpn{program}}\\
  \bnfprod{flx}        {\bnfts{\texttt{flx}} \bnfsp \bnfpn{id} \bnfsp \bnfpn{ctx} \bnfsp \bnfpn{worker} \bnfsp \bnftd{eol} \bnfsp \bnfpn{streams} \bnfsp \bnftd{eol} \bnfsp \bnfpn{fn}}\\
  \bnfprod{worker}     {\bnfts{\texttt{on}} \bnfsp \bnfpn{id} \bnfor \bnftd{empty string}}\\
  \bnfprod{streams}    {\bnfts{\texttt{null}} \bnfor \bnfpn{stream} \bnfor \bnfpn{stream} \bnfsp \bnftd{eol} \bnfsp \bnfpn{streams}}\\
  \bnfprod{stream}     {\bnfpn{op} \bnfsp \bnfpn{dest} \bnfsp [\bnfpn{msg}]}\\
  \bnfprod{dest}       {\bnfpn{list}}\\
  \bnfprod{ctx}        {\bnfts{\texttt{\{}} \bnfpn{list} \bnfts{\texttt{\}}}}\\
  \bnfprod{msg}        {\bnfts{\texttt{[}} \bnfpn{list} \bnfts{\texttt{]}}}\\
  \bnfprod{list}       {\bnfpn{id} \bnfor \bnfpn{id} \bnfsp \bnfts{,} \bnfsp \bnfpn{list}}\\
  \bnfprod{op}         {\bnfts{\texttt{>}\texttt{>}} \bnfor \bnfts{\texttt{-}\texttt{>}}}\\
  \bnfprod{id}         {\bnftd{Javascript identifier}}\\
  \bnfprod{fn}         {\bnftd{Javascript and stream syntax}}\\
\end{bnf*}
\vspace{-1.5\baselineskip}~\\

Fluxions are the stages in a pipeline architecture.
The streams of messages between fluxions are carried by the messaging system.

\subsection{Messaging system}

In a distributed approach, the messages between fluxions would be carried over a distributed message broker.
But because this execution model intends only to simulate a distributed execution environement, we simplify a distributed message broker with a centralised message queue.
% The messaging system is the core of the execution model.
% It carries messages and invokes fluxions at reception.
The messaging system sends messages to the isolated worker hosting the destination fluxion.
The worker containing the messaging system is itself a worker, and contains locally fluxion that cannot be isolated from the network interfaces.
% Using a message queue allows to execute multiple processing chains fairly and concurrently, without difference in scheduling local messages, or network messages.
The life cycle of a fluxional application is illustrated in figure \ref{fig:MesSys}.

\begin{figure}[h!]
  \includegraphics[width=\linewidth]{ressources/schema-message.pdf}
  \caption{Messaging system details}
  \label{fig:MesSys}
\end{figure}

The messaging system carries messages based on the names of the recipient fluxions.
If two fluxions share the same name, it would lead to a conflicting situation for the messaging system.
Every fluxion needs to be registered with a unique name.
This registration associates a processing function with a unique name and an initial \textit{context}.
The registration is done using the function \texttt{register(<name>, <fn>, <context>)}, \circled{1}.
% A fluxion can dynamically register other fluxions

To trigger a chain of fluxions, a message is sent using the function \texttt{start(<msg>)}, \circled{2}.
This first message represent the incoming of a request from a user.
% This function pushes a first message in the queue.
The system dequeues this message and dispatch it to the destination fluxion, \circled{3} and \circled{4}.
The recipient function sends back messages from the isolated worker using the function \texttt{post(<msg>)}, \circled{5}, to be enqueued in the centralised message queue, \circled{6}.
The system loops through steps \circled{3} and \circled{4} until the queue is empty.
This cycle starts again for each new incoming request causing a \textit{start} message.

Algorithms \ref{alg:parcours} and \ref{alg:traitement} describe the behavior of the messaging system after the \texttt{start} function invocation.

\begin{algorithm}
\caption{Message queue walking algorithm}
\label{alg:parcours}
\begin{algorithmic}
\Function{loopMessage}{\null}
\While{$msg$ \textbf{presents in} $msgQueue$}
\State $msg \gets$ \Call{dequeue}{\null} \Comment{\circled{3}}
\State \Call{ProcessMsg}{$msg$}
\EndWhile
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Message processing algorithm}
\label{alg:traitement}
\begin{algorithmic}
\Function{processMsg}{$msg$}
\For{$dest$ \textbf{in} $msg.dest$}
\State $worker \gets lookup(dest)$
\State \Call{worker.send}{$fluxion, msg.body$} \Comment{\circled{4}}
% \State $message \gets$ \Call{exec}{$fluxion, msg.body$} \Comment{\circled{4} \& \circled{5}}
% \State \Call{enqueue}{$message$} \Comment{\circled{6}}
\EndFor
\EndFunction
\end{algorithmic}
\end{algorithm}

\subsection{Service example}

To illustrate the fluxional execution model, and the compiler we present an example of a simple web application.
This application reads the file containing its own source code, and sends it back along with a request counter.

The original source code of this application is available on github\cite{flx-example}, and in listing \ref{lst:source}.
In this source code, some points are worth noticing.

\begin{itemize}
  \item The \texttt{handler} function, line 5 to 11, contains the logic we want to split into the fluxional processing chain.
  It receives the user request in the variable \texttt{res} which is used by the last function of the chain, \texttt{reply}.
  \item The \texttt{count} object at line 3 is a persistent memory that increments the request counter.
  This object needs to be mapped to a fluxion \textit{execution context} in the fluxional execution model.
  \item The \texttt{app.get} and \texttt{app.send} methods, respectively line 5 and 9, interface the application with the clients.
  The processing chain of functions occurs between these two functions : $\texttt{get} \twoheadrightarrow \texttt{handler} \to \texttt{readFile} \to \texttt{reply} \to \texttt{send}$.
\end{itemize}

\includecode{js,
  caption={Simple web application. \textnormal{this application replies to every user request with its own source code and the value of a request counter}},
  label={lst:source}
}
{../../flx-example/source.js}

This application is transformed manually into the fluxions chain depicted in Figure \ref{fig:fluxions}.
We expect a similar result with the compiler described in section \ref{section:compiler}.
Circles represent registered fluxions.
Envelope symbols represent messages streams between fluxions with the variables transmitted from one fluxion to the other.
The square in the messaging system holds the \textit{context} of the \texttt{reply} fluxion.
When a new REST request \texttt{GET} is received, a \texttt{start} message triggers the flow.
The \texttt{handler} fluxion receives this \texttt{start} message, reads the source file and forwards it to the \texttt{reply} fluxion which increments the counter, and sends the result back.
Each fluxion propagates the necessary values from one fluxion to the other exclusively by messages.
Horizontal dashed lines show virtual transmission of messages between fluxions although they all go through the messaging system.

\begin{figure}[h!]
  \includegraphics[width=\linewidth]{ressources/flux.pdf}
  \caption{Fluxions chain manually extracted from the example application}
  \label{fig:fluxions}
\end{figure}

\begin{code}[flx, caption={Manual transformation of the example application in our high-level fluxional language},label={lst:fluxional}]
flx get
>> handler [res]
  var app = require('express')(),
      fs = require('fs'),
      count = 0;

\\@\label{lst:fluxional-streamtohandler}@  app.get('/', >> handler);
  app.listen(8080);
  console.log('>> listening 8080');

flx handler
-> reply [res]
  function handler(req, res) {
\\@\label{lst:fluxional-readfile}@      fs.readFile(__filename, -> reply);
  }

flx reply {count}
-> null
  function reply(error, data) {
\\@\label{lst:fluxional-counter}@    count += 1;
    var code = ('' + data).replace(/\n/g, '<br>').replace(/ /g, '&nbsp');
\\@\label{lst:fluxional-ressend}@    res.send('downloaded ' + count + ' times<br><br><code>' + code + '</code>');
  }
\end{code}

The application is organized as follow :
\begin{itemize}
  \item The \texttt{get} fluxion is the \textit{root} fluxion.
  It initializes the application to listen for user requests by calling \texttt{app.get}.
  Every request is forwarded on the stream to the \texttt{handler} fluxion, line \ref{lst:fluxional-streamtohandler}.
  \item The \texttt{handler} fluxion reads the file containing the source code of the application, and forwards the result to the \texttt{reply} fluxion, line \ref{lst:fluxional-readfile}.
  \item The \texttt{reply} fluxion increments the counter, line \ref{lst:fluxional-counter}, formats the reply, and sends it back to the user using the function \texttt{res.send}, line \ref{lst:fluxional-ressend}.
\end{itemize}

Our goal, as described in the introduction, is not to propose a new programming paradigm with this high-level language but to automate the architecture shift with a compiler.